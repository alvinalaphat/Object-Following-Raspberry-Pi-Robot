The application demonstrated in the project selection demo used an algorithm called
Circular Hough transform to detect a circular object in a frame and it then applied a yellow mask similar to what we did in practical 1 to identify
the yellow tennis ball. The approach will be to use the similar circular hough transform algorithm to identify the shape of the ball, a yellow mask to identify the object,consistent lighting conditions, a contrasting background, motors to move towards the ball, and wheels to make turns and keep the ball in the center of the camera frame attached to the raspberry Pi. 

We will collect 20 images of our hands holding a tennis ball in a training as well as test set so we can see if there's variance when a hand is in the frame of the camera. We will do it on a white background as that will probably be the background of the walls when we do testing. We will need good lighting especially since yellow and white are similar. 

We also have a dataset of tennis balls obtained from kaggle.com at this link: https://www.kaggle.com/code/cuauhtemoccontreras/tennis-ball-detection/data
